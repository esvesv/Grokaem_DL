{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0550bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "720fd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Grokking-Deep-Learning/reviews.txt', encoding='utf-8') as file:\n",
    "    raw_reviews = list(map(str.strip, file.readlines()))\n",
    "#     raw_reviews = file.readlines()\n",
    "    \n",
    "with open('Grokking-Deep-Learning/labels.txt', encoding='utf-8') as file:\n",
    "    raw_labels = list(map(str.strip, file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620905f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('raw_reviews.pkl', 'wb') as file:\n",
    "#     pickle.dump(raw_reviews, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb12143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = list(map(lambda x: set(x.split(' ')), raw_reviews))\n",
    "\n",
    "tokens = [set(x.split(' ')) for x in raw_reviews] # список множеств слов из каждой статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f09182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokens.pkl', 'wb') as file:\n",
    "    pickle.dump(tokens, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40fa72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab1 = set()\n",
    "# for sent in tokens:\n",
    "#     for word in sent:\n",
    "#         if (len(word) > 0):\n",
    "#             vocab1.add(word)\n",
    "# vocab1 = list(vocab1)\n",
    "\n",
    "vocab = list({word for token in tokens for word in token if len(word) > 0}) # словарь всех слов во всех статьях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4615ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2index1 = {}\n",
    "# for i, word in enumerate(vocab):\n",
    "#     word2index1[word] = i\n",
    "\n",
    "word2index = {key: value for value, key in enumerate(vocab)} # словарь индексов всех слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b30a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dataset1 = list()\n",
    "# for sent in tokens:\n",
    "#     sent_indices = list()\n",
    "#     for word in sent:\n",
    "#         try:\n",
    "#             sent_indices.append(word2index[word])\n",
    "#         except:\n",
    "#             ''\n",
    "#     input_dataset1.append(list(set(sent_indices)))\n",
    "\n",
    "# перекодировка tokens из слов и индексы\n",
    "\n",
    "input_dataset = [[word2index[word] for word in token if len(word) > 0] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b11fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = [1 if label == 'positive' else 0 for label in raw_labels] # оцифровка target\n",
    "\n",
    "inputs = np.zeros((len(input_dataset[:-1000]), len(vocab)))\n",
    "for i in range(inputs.shape[0]):\n",
    "    for word in input_dataset[:-1000][i]:\n",
    "        inputs[i][word] = 1\n",
    "\n",
    "tests = np.zeros((len(input_dataset[-1000:]), len(vocab)))\n",
    "for i in range(tests.shape[0]):\n",
    "    for word in input_dataset[-1000:][i]:\n",
    "        tests[i][word] = 1\n",
    "\n",
    "targets = np.array(target_dataset[:-1000]).reshape(-1, 1)\n",
    "outputs = np.zeros((targets.shape[0], 2))\n",
    "for output, target in zip(outputs, targets):\n",
    "    output[target] = 1\n",
    "    \n",
    "test_targets = np.array(target_dataset[-1000:]).reshape(-1, 1)\n",
    "test_outputs = np.zeros((test_targets.shape[0], 2))\n",
    "for test_output, test_target in zip(test_outputs, test_targets):\n",
    "    test_output[test_target] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ddabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(x):\n",
    "    return (x > 0)\n",
    "\n",
    "lr = 0.0001\n",
    "iterations = 33\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "weights_0_1 = 0.02 * np.random.random((len(vocab), hidden_size)) - 0.01\n",
    "weights_1_2 = 0.02 * np.random.random((hidden_size, 2)) - 0.01\n",
    "\n",
    "func = lambda x: np.sum(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3514bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0 Error: 852.2775829890 Train-Acc: 0.99500 Test-Acc: 0.84600\n",
      "I: 1 Error: 838.8561814459 Train-Acc: 0.99500 Test-Acc: 0.84700\n",
      "I: 2 Error: 824.4363008779 Train-Acc: 0.99521 Test-Acc: 0.84600\n",
      "I: 3 Error: 810.5202046100 Train-Acc: 0.99546 Test-Acc: 0.84600\n",
      "I: 4 Error: 800.2404583166 Train-Acc: 0.99562 Test-Acc: 0.84600\n",
      "I: 5 Error: 787.7927482098 Train-Acc: 0.99575 Test-Acc: 0.84600\n",
      "I: 6 Error: 774.8183469298 Train-Acc: 0.99596 Test-Acc: 0.84600\n",
      "I: 7 Error: 764.8222515581 Train-Acc: 0.99608 Test-Acc: 0.84600\n",
      "I: 8 Error: 751.1662305752 Train-Acc: 0.99621 Test-Acc: 0.84600\n",
      "I: 9 Error: 739.0906594470 Train-Acc: 0.99625 Test-Acc: 0.84600\n",
      "I: 10 Error: 728.3990546292 Train-Acc: 0.99646 Test-Acc: 0.84600\n",
      "I: 11 Error: 716.4951013154 Train-Acc: 0.99654 Test-Acc: 0.84700\n",
      "I: 12 Error: 708.5259363394 Train-Acc: 0.99667 Test-Acc: 0.84700\n",
      "I: 13 Error: 696.3593940824 Train-Acc: 0.99675 Test-Acc: 0.84700\n",
      "I: 14 Error: 684.4084253580 Train-Acc: 0.99675 Test-Acc: 0.84500\n",
      "I: 15 Error: 675.9976717148 Train-Acc: 0.99683 Test-Acc: 0.84600\n",
      "I: 16 Error: 664.8152388720 Train-Acc: 0.99696 Test-Acc: 0.84300\n",
      "I: 17 Error: 656.1949896946 Train-Acc: 0.99700 Test-Acc: 0.84300\n",
      "I: 18 Error: 644.2508463628 Train-Acc: 0.99708 Test-Acc: 0.84200\n",
      "I: 19 Error: 637.2916646183 Train-Acc: 0.99717 Test-Acc: 0.84200\n",
      "I: 20 Error: 625.2672987428 Train-Acc: 0.99733 Test-Acc: 0.84100\n",
      "I: 21 Error: 619.2269574631 Train-Acc: 0.99733 Test-Acc: 0.84200\n",
      "I: 22 Error: 607.2171494815 Train-Acc: 0.99746 Test-Acc: 0.84200\n",
      "I: 23 Error: 601.1524532643 Train-Acc: 0.99750 Test-Acc: 0.84100\n",
      "I: 24 Error: 589.4919225017 Train-Acc: 0.99775 Test-Acc: 0.84100\n",
      "I: 25 Error: 582.8506442238 Train-Acc: 0.99783 Test-Acc: 0.84100\n",
      "I: 26 Error: 575.4179981130 Train-Acc: 0.99783 Test-Acc: 0.84100\n",
      "I: 27 Error: 569.2740750619 Train-Acc: 0.99792 Test-Acc: 0.84100\n",
      "I: 28 Error: 555.7491853570 Train-Acc: 0.99804 Test-Acc: 0.84100\n",
      "I: 29 Error: 551.6310659810 Train-Acc: 0.99813 Test-Acc: 0.84100\n",
      "I: 30 Error: 542.1505084207 Train-Acc: 0.99813 Test-Acc: 0.84100\n",
      "I: 31 Error: 536.2836041640 Train-Acc: 0.99817 Test-Acc: 0.84100\n",
      "I: 32 Error: 529.6660166295 Train-Acc: 0.99825 Test-Acc: 0.84100\n",
      "I: 33 Error: 522.3270337655 Train-Acc: 0.99829 Test-Acc: 0.84100\n",
      "I: 34 Error: 510.0639831778 Train-Acc: 0.99838 Test-Acc: 0.84100\n",
      "I: 35 Error: 507.8072617391 Train-Acc: 0.99838 Test-Acc: 0.84100\n",
      "I: 36 Error: 501.9417195648 Train-Acc: 0.99850 Test-Acc: 0.84000\n",
      "I: 37 Error: 492.2909709499 Train-Acc: 0.99858 Test-Acc: 0.84000\n",
      "I: 38 Error: 486.0707494071 Train-Acc: 0.99862 Test-Acc: 0.84000\n",
      "I: 39 Error: 478.8989650727 Train-Acc: 0.99871 Test-Acc: 0.84000\n",
      "I: 40 Error: 476.1225816612 Train-Acc: 0.99875 Test-Acc: 0.83900\n",
      "I: 41 Error: 469.0504627590 Train-Acc: 0.99883 Test-Acc: 0.83900\n",
      "I: 42 Error: 460.9835439551 Train-Acc: 0.99879 Test-Acc: 0.83900\n",
      "I: 43 Error: 450.0639824906 Train-Acc: 0.99883 Test-Acc: 0.83800\n",
      "I: 44 Error: 454.8180247713 Train-Acc: 0.99887 Test-Acc: 0.83400\n",
      "I: 45 Error: 441.6657724277 Train-Acc: 0.99887 Test-Acc: 0.83800\n",
      "I: 46 Error: 442.9752064402 Train-Acc: 0.99892 Test-Acc: 0.83300\n",
      "I: 47 Error: 426.1777788311 Train-Acc: 0.99892 Test-Acc: 0.83700\n",
      "I: 48 Error: 435.8908291798 Train-Acc: 0.99892 Test-Acc: 0.83300\n",
      "I: 49 Error: 416.0125006488 Train-Acc: 0.99892 Test-Acc: 0.83600\n",
      "I: 50 Error: 414.8816807645 Train-Acc: 0.99892 Test-Acc: 0.83300\n",
      "I: 51 Error: 422.3177005506 Train-Acc: 0.99900 Test-Acc: 0.83000\n",
      "I: 52 Error: 398.2232627923 Train-Acc: 0.99900 Test-Acc: 0.83400\n",
      "I: 53 Error: 407.1402269364 Train-Acc: 0.99908 Test-Acc: 0.83000\n",
      "I: 54 Error: 394.0041424168 Train-Acc: 0.99908 Test-Acc: 0.83400\n",
      "I: 55 Error: 389.1059461716 Train-Acc: 0.99913 Test-Acc: 0.83300\n",
      "I: 56 Error: 398.4560637366 Train-Acc: 0.99921 Test-Acc: 0.82800\n",
      "I: 57 Error: 371.1751948590 Train-Acc: 0.99921 Test-Acc: 0.83100\n",
      "I: 58 Error: 388.4469323803 Train-Acc: 0.99921 Test-Acc: 0.82900\n",
      "I: 59 Error: 368.3306682924 Train-Acc: 0.99933 Test-Acc: 0.83200\n",
      "I: 60 Error: 376.6668372616 Train-Acc: 0.99933 Test-Acc: 0.82800\n",
      "I: 61 Error: 355.5399644493 Train-Acc: 0.99942 Test-Acc: 0.83300\n",
      "I: 62 Error: 358.3445288234 Train-Acc: 0.99942 Test-Acc: 0.83100\n",
      "I: 63 Error: 374.4971386545 Train-Acc: 0.99942 Test-Acc: 0.82800\n",
      "I: 64 Error: 339.2626400068 Train-Acc: 0.99946 Test-Acc: 0.83400\n",
      "I: 65 Error: 362.7588781686 Train-Acc: 0.99950 Test-Acc: 0.82900\n",
      "I: 66 Error: 333.1545608479 Train-Acc: 0.99954 Test-Acc: 0.83300\n",
      "I: 67 Error: 348.3128529940 Train-Acc: 0.99950 Test-Acc: 0.82900\n",
      "I: 68 Error: 327.2726922278 Train-Acc: 0.99954 Test-Acc: 0.83200\n",
      "I: 69 Error: 354.4112858924 Train-Acc: 0.99958 Test-Acc: 0.82800\n",
      "I: 70 Error: 314.3874160347 Train-Acc: 0.99954 Test-Acc: 0.83200\n",
      "I: 71 Error: 345.0700635311 Train-Acc: 0.99962 Test-Acc: 0.82800\n",
      "I: 72 Error: 316.9999283548 Train-Acc: 0.99958 Test-Acc: 0.83200\n",
      "I: 73 Error: 305.9355396790 Train-Acc: 0.99958 Test-Acc: 0.83100\n",
      "I: 74 Error: 349.3937603157 Train-Acc: 0.99975 Test-Acc: 0.82800\n",
      "I: 75 Error: 299.3296285061 Train-Acc: 0.99962 Test-Acc: 0.83000\n",
      "I: 76 Error: 302.7467317703 Train-Acc: 0.99967 Test-Acc: 0.82800\n",
      "I: 77 Error: 334.1820559576 Train-Acc: 0.99975 Test-Acc: 0.82700\n",
      "I: 78 Error: 281.7060599795 Train-Acc: 0.99967 Test-Acc: 0.82900\n",
      "I: 79 Error: 326.5026734899 Train-Acc: 0.99975 Test-Acc: 0.82700\n",
      "I: 80 Error: 285.6323226962 Train-Acc: 0.99971 Test-Acc: 0.82800\n",
      "I: 81 Error: 286.7381466064 Train-Acc: 0.99971 Test-Acc: 0.82700\n",
      "I: 82 Error: 321.3061383777 Train-Acc: 0.99979 Test-Acc: 0.82800\n",
      "I: 83 Error: 263.8323471588 Train-Acc: 0.99971 Test-Acc: 0.82900\n",
      "I: 84 Error: 322.6690073206 Train-Acc: 0.99979 Test-Acc: 0.82600\n",
      "I: 85 Error: 260.6820984410 Train-Acc: 0.99971 Test-Acc: 0.82800\n",
      "I: 86 Error: 303.4155336257 Train-Acc: 0.99979 Test-Acc: 0.82700\n",
      "I: 87 Error: 262.4815111671 Train-Acc: 0.99979 Test-Acc: 0.82800\n",
      "I: 88 Error: 300.0501062424 Train-Acc: 0.99983 Test-Acc: 0.82600\n",
      "I: 89 Error: 262.6580430163 Train-Acc: 0.99979 Test-Acc: 0.82800\n",
      "I: 90 Error: 247.2640820204 Train-Acc: 0.99983 Test-Acc: 0.82800\n",
      "I: 91 Error: 337.1579825843 Train-Acc: 0.99983 Test-Acc: 0.82200\n",
      "I: 92 Error: 233.3516089233 Train-Acc: 0.99979 Test-Acc: 0.83200\n",
      "I: 93 Error: 314.3277719216 Train-Acc: 0.99983 Test-Acc: 0.82300\n",
      "I: 94 Error: 264.5528920142 Train-Acc: 0.99987 Test-Acc: 0.82600\n",
      "I: 95 Error: 226.0375064287 Train-Acc: 0.99979 Test-Acc: 0.83200\n",
      "I: 96 Error: 344.8612854959 Train-Acc: 0.99983 Test-Acc: 0.82200\n",
      "I: 97 Error: 231.1767061375 Train-Acc: 0.99983 Test-Acc: 0.82500\n",
      "I: 98 Error: 229.5222845446 Train-Acc: 0.99983 Test-Acc: 0.82900\n",
      "I: 99 Error: 324.0344373371 Train-Acc: 0.99987 Test-Acc: 0.82100\n"
     ]
    }
   ],
   "source": [
    "for iter in range(iterations):\n",
    "    for i in range(int(len(inputs) / batch_size)):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min(batch_start + batch_size, len(inputs))\n",
    "        \n",
    "        notes = inputs[batch_start: batch_end]\n",
    "        goal_pred = outputs[batch_start: batch_end]\n",
    "        \n",
    "        layer_0 = inputs[batch_start: batch_end]\n",
    "        layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "        layer_2 = layer_1.dot(weights_1_2)\n",
    "        \n",
    "        layer_2_delta = (layer_2 - goal_pred)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 -= lr * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= lr * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    # Проверка точности на всем массиве тренировоных данных\n",
    "    layer_0 = inputs\n",
    "    layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "    layer_2 = layer_1.dot(weights_1_2)\n",
    "\n",
    "    error = np.sum((layer_2 - outputs) ** 2)\n",
    "    correct_train = np.sum(np.array([np.argmax(x) for x in outputs]).reshape(-1, 1) == np.array([np.argmax(x) for x in layer_2]).reshape(-1, 1)) / len(outputs)\n",
    "\n",
    "    # Проверка точности на тестовых данных\n",
    "    layer_0 = tests\n",
    "    layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "    layer_2 = layer_1.dot(weights_1_2)\n",
    "\n",
    "    correct_test = np.sum(test_targets == np.array([np.argmax(x) for x in layer_2]).reshape(-1, 1)) / len(test_targets)\n",
    "    sys.stdout.write(f'I: {iter} Error: {error:.10f} Train-Acc: {correct_train:.5f} Test-Acc: {correct_test:.5f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e830a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac55bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('word2index.pkl', 'wb') as file:\n",
    "#     pickle.dump(word2index, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1abdb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('weights_0_1.pkl', 'wb') as file:\n",
    "#     pickle.dump(weights_0_1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30b76597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('weights_1_2.pkl', 'wb') as file:\n",
    "#     pickle.dump(weights_1_2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b922044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights_0_1.pkl', 'rb') as file:\n",
    "    weights_0_1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c483abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights_1_2.pkl', 'rb') as file:\n",
    "    weights_1_2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6cd2521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0 = inputs\n",
    "layer_1 = relu(layer_0.dot(weights_0_1))\n",
    "layer_2 = layer_1.dot(weights_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69495c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735416666666666"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = np.sum(np.array([np.argmax(x) for x in outputs]).reshape(-1, 1) == np.array([np.argmax(x) for x in layer_2]).reshape(-1, 1)) / len(outputs)\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "968d2556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9112"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf6e38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22951"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e975b159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61604"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ff69ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44399"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01858756",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = weights_0_1[9112] - weights_0_1[22951] + weights_0_1[44399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e214de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "queen = weights_0_1[61604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2266cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06784773860284869"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((pred - queen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26decc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
